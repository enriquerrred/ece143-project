{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "#import torch\n",
    "from numpy import genfromtxt\n",
    "import data_loader as dl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "#from statsmodels.tools import categorical\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predn, truth):\n",
    "    '''\n",
    "    Computes classification accuracy given 2  numpy arrays where the arguments are predictions and ground\n",
    "    truth.\n",
    "    \n",
    "    Args:\n",
    "        predn : numpy ndarray of predictions of class labels\n",
    "        truth : ground tuth numpy ndarray of class labels\n",
    "        \n",
    "    Returns:\n",
    "        accuracy : Float value denoting classification accuracy\n",
    "    '''\n",
    "    \n",
    "    assert isinstance(predn,np.ndarray) and isinstance(truth,np.ndarray)\n",
    "    assert(len(predn) == len(truth))\n",
    "    assert(predn.dtype == 'int64'and truth.dtype == 'int64')\n",
    "    \n",
    "    \n",
    "    \n",
    "    samples = predn.shape\n",
    "    return (np.sum(1*(predn == truth))/samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "handle = dl.DataLoader('./WA_Fn-UseC_-HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, ltrain,fnames,newfnames = handle.get_data()\n",
    "test,ltest,fnames,newfnames = handle.get_data(mode = 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLClassifier():\n",
    "    def __init__(self,Xtrain,ytrain,Xtest,ytest,fnames = None,newfnames = None):\n",
    "        '''\n",
    "        Initialize a multipurpose classifier from training data,training labels, testing data and testing\n",
    "        labels. Provide the arguments fnames and newfnames from the data loader function.\n",
    "        \n",
    "        Args:\n",
    "            Xtrain : Training matrix in the form n_sumples x n_features\n",
    "            ltrain : Labels of training matrix of the form (n_samples,)\n",
    "            Xtest : Testing matrix in the form of n_samples x  n_features\n",
    "            ltest : Labels of testing matrix of the form (n_samples,)\n",
    "            fnames : Provide the fnames returned by the data loader (Only if data needs to be plotted)\n",
    "            newfnames : Provide the newfnames returned by the data loader (Only if data needs to be plotted)\n",
    "        Returns:\n",
    "            Instance of the multipurpose classifier\n",
    "        '''\n",
    "        \n",
    "        assert isinstance(Xtrain,np.ndarray) and isinstance(ytrain,np.ndarray) and isinstance(Xtest,np.ndarray) and isinstance(ytest,np.ndarray)\n",
    "        assert (len(Xtrain.shape) == 2) and (len(Xtest.shape) == 2)\n",
    "        assert (Xtrain.shape[0] == ytrain.shape[0]) and (Xtest.shape[0] == ytest.shape[0])\n",
    "        \n",
    "        assert(ytrain.dtype == 'int64') and (ytest.dtype == 'int64')\n",
    "        \n",
    "        \n",
    "        self._train = Xtrain\n",
    "        self._test  = Xtest\n",
    "        self._ltrain = ytrain\n",
    "        self._ltest = ytest\n",
    "        self._forest = None\n",
    "        self._fnames = fnames\n",
    "        self._newfnames = newfnames\n",
    "        \n",
    "        \n",
    "    def ExtraTrees(self,mode = 'v'):\n",
    "        '''\n",
    "        Builds an extra trees classifier and outputs accuracies into a text file\n",
    "        \n",
    "        Args:\n",
    "            mode : v (default) : Accuracies printed on screen\n",
    "                   q : Quiet mode\n",
    "        Returns:\n",
    "            Alters the instance of the object to make it into an extra trees classifier. Changes differ only\n",
    "            when PlotFeatureImportance is called.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert isinstance(mode,str)\n",
    "        assert (mode == 'v') or (mode == 'q')\n",
    "        \n",
    "        forest = ExtraTreesClassifier(n_estimators = 25,max_features= None,oob_score = True,bootstrap= True)\n",
    "        forest.fit(self._train,self._ltrain)\n",
    "        test_pred = forest.predict(self._test)\n",
    "        test_acc = compute_accuracy(test_pred,self._ltest)\n",
    "        train_pred = forest.predict(self._train)\n",
    "        train_acc = compute_accuracy(train_pred,self._ltrain)\n",
    "        self._forest = forest\n",
    "\n",
    "        fname = 'ExtraTrees_result.txt'\n",
    "        \n",
    "        if(mode == 'q'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for ExtraTrees Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "                \n",
    "        if(mode == 'v'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for ExtraTrees Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "            print(\"Training accuracy for ExtraTrees Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc))\n",
    "\n",
    "            \n",
    "    def RandomForest(self,mode = 'v'):\n",
    "        '''\n",
    "        Builds an random forest classifier and outputs accuracies into a text file\n",
    "        \n",
    "        Args:\n",
    "            mode : v (default) : Accuracies printed on screen\n",
    "                   q : Quiet mode\n",
    "        Returns:\n",
    "            Alters the instance of the object to make it into an random forest classifier. Changes differ only\n",
    "            when PlotFeatureImportance is called.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert isinstance(mode,str)\n",
    "        assert (mode == 'v') or (mode == 'q')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        forest = RandomForestClassifier(n_estimators = 20,max_depth= None,max_features= None,oob_score = True,class_weight = 'balanced')\n",
    "        forest.fit(self._train,self._ltrain)\n",
    "        test_pred = forest.predict(self._test)\n",
    "        test_acc = compute_accuracy(test_pred,self._ltest)\n",
    "        train_pred = forest.predict(self._train)\n",
    "        train_acc = compute_accuracy(train_pred,self._ltrain)\n",
    "        self._forest = forest\n",
    "\n",
    "        \n",
    "        fname = 'RandomForest_result.txt'\n",
    "        \n",
    "        if(mode == 'q'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for RandomForest Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "                \n",
    "        if(mode == 'v'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for RandomForest Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "            print(\"Training accuracy for RandomForest Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc))        \n",
    "            \n",
    "    def LinearSVM(self,mode = 'v'):\n",
    "        '''\n",
    "        Builds an linear support vector machine classifier and outputs accuracies into a text file\n",
    "        \n",
    "        Args:\n",
    "            mode : v (default) : Accuracies printed on screen\n",
    "                   q : Quiet mode\n",
    "        Returns:\n",
    "            Alters the instance of the object to make it into an linear support vector machine classifier. Changes differ only\n",
    "            when PlotFeatureImportance is called.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert isinstance(mode,str)\n",
    "        assert (mode == 'v') or (mode == 'q')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        forest = LinearSVC(dual = False,max_iter = 7000,C=0.1,penalty='l1')\n",
    "        forest.fit(self._train,self._ltrain)\n",
    "        test_pred = forest.predict(self._test)\n",
    "        test_acc = compute_accuracy(test_pred,self._ltest)\n",
    "        train_pred = forest.predict(self._train)\n",
    "        train_acc = compute_accuracy(train_pred,self._ltrain)\n",
    "        self._forest = forest\n",
    "        \n",
    "        \n",
    "        fname = 'LinearSVM_result.txt'\n",
    "        \n",
    "        if(mode == 'q'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for LinearSVM Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "                \n",
    "        if(mode == 'v'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for LinearSVM Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "            print(\"Training accuracy for LinearSVM Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc))        \n",
    "    \n",
    "    def RadSVM(self,mode = 'v'):\n",
    "        '''\n",
    "        Builds an Radial basis function SVM and outputs accuracies into a text file\n",
    "        \n",
    "        Args:\n",
    "            mode : v (default) : Accuracies printed on screen\n",
    "                   q : Quiet mode\n",
    "        Returns:\n",
    "            Alters the instance of the object to make it into an Radial basis function SVM. Changes differ only\n",
    "            when PlotFeatureImportance is called.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert isinstance(mode,str)\n",
    "        assert (mode == 'v') or (mode == 'q')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        forest = SVC(gamma = 'scale')\n",
    "        forest.fit(self._train,self._ltrain)\n",
    "        test_pred = forest.predict(self._test)\n",
    "        test_acc = compute_accuracy(test_pred,self._ltest)\n",
    "        train_pred = forest.predict(self._train)\n",
    "        train_acc = compute_accuracy(train_pred,self._ltrain)\n",
    "        self._forest = forest\n",
    "        \n",
    "        \n",
    "        \n",
    "        fname = 'RadSVM_result.txt'\n",
    "        \n",
    "        if(mode == 'q'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for Radial Basis Function SVM Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "                \n",
    "        if(mode == 'v'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for Radial Basis Function SVM Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "            print(\"Training accuracy for Radial Basis Function SVM Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc))\n",
    "    \n",
    "    \n",
    "    def LogRegression(self,mode = 'v'):\n",
    "        '''\n",
    "        Builds an Logistic Regression Classifier and outputs accuracies into a text file\n",
    "        \n",
    "        Args:\n",
    "            mode : v (default) : Accuracies printed on screen\n",
    "                   q : Quiet mode\n",
    "        Returns:\n",
    "            Alters the instance of the object to make it into an Logistic Regression Classifier. Changes differ only\n",
    "            when PlotFeatureImportance is called.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        assert isinstance(mode,str)\n",
    "        assert (mode == 'v') or (mode == 'q')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        forest = LogisticRegression(solver = 'lbfgs', max_iter = 500)\n",
    "        forest.fit(self._train,self._ltrain)\n",
    "        test_pred = forest.predict(self._test)\n",
    "        test_acc = compute_accuracy(test_pred,self._ltest)\n",
    "        train_pred = forest.predict(self._train)\n",
    "        train_acc = compute_accuracy(train_pred,self._ltrain)\n",
    "        self._forest = forest\n",
    "        \n",
    "        \n",
    "        fname = 'LogRegression_result.txt'\n",
    "        \n",
    "        if(mode == 'q'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for Logistic Regression Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "                \n",
    "        if(mode == 'v'):\n",
    "            with open(fname,'w') as f:\n",
    "                print(\"Training accuracy for Logistic Regression Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc),file = f)\n",
    "            print(\"Training accuracy for Logistic Regression Classifier is %2.5f\\nTesting Accuracy is %2.5f\"%(train_acc,test_acc))\n",
    "    \n",
    "    def PlotFeatureImportances(self):\n",
    "        '''\n",
    "        Plots the feature importances only for the extra trees or random trees classiffier\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "        Returns:\n",
    "            None\n",
    "        Side Effects:\n",
    "            Displays an image consisting of feature importances and also saves same to a file.\n",
    "        \n",
    "        '''\n",
    "        assert (self._forest != None)\n",
    "        \n",
    "        assert type(self._forest) == sklearn.ensemble.forest.ExtraTreesClassifier or type(self._forest) == sklearn.ensemble.forest.RandomForestClassifier\n",
    " \n",
    "        forest = self._forest\n",
    "        fnames = self._fnames\n",
    "        newfnames = self._newfnames\n",
    "        \n",
    "        importances = forest.feature_importances_\n",
    "        updated_importances = []\n",
    "        categorical_importances =dict()\n",
    "        count = [0]*8\n",
    "        for value,name in zip(importances,fnames):\n",
    "            if(name[-1] != '0'):\n",
    "                updated_importances.append(value)\n",
    "                continue\n",
    "            else:\n",
    "                b = name.split('_')\n",
    "                try:\n",
    "                    categorical_importances[b[0]][0] +=  value\n",
    "                    categorical_importances[b[0]][1] += 1\n",
    "                except KeyError:\n",
    "                    categorical_importances[b[0]] = [value,1]\n",
    "                    #categorical_importances[b[0]][1] = 1\n",
    "        for key,val in zip(categorical_importances.keys(),categorical_importances.values()):\n",
    "            categorical_importances[key] = categorical_importances[key][0]/categorical_importances[key][1]\n",
    "        updated_importances = updated_importances + list(categorical_importances.values())\n",
    "\n",
    "        std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                     axis=0)\n",
    "        importances = np.asarray(updated_importances)\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        indices = indices[:10]\n",
    "        # Print the feature ranking\n",
    "        fig,ax = plt.subplots()\n",
    "        tosave  = './feature_importance'\n",
    "        print(\"Feature ranking:\")\n",
    "\n",
    "        for f in range(10):\n",
    "            print(\"%d. feature %d - %s (%f)\" % (f + 1, indices[f], newfnames[indices[f]],importances[indices[f]]))\n",
    "\n",
    "        # Plot the feature importances of the forest\n",
    "        #plt.figure()\n",
    "        ax.set_title(\"Feature importances\")\n",
    "        ax.bar(range(10), importances[indices],yerr=std[indices], align=\"center\",\n",
    "               color=\"r\")\n",
    "        plt.xticks(range(10), indices)\n",
    "        ax.set_xlim([-1, 10])\n",
    "        #plt.show()\n",
    "        plt.savefig(tosave)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
